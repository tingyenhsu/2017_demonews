{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Documentation : https://api.mongodb.com/python/current/tutorial.html  https://docs.mongodb.com/v3.0/reference/method/db.dropDatabase/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 寫進mongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pymongo  #version:3.4.0\n",
    "from pymongo import MongoClient\n",
    "client = pymongo.MongoClient()\n",
    "# from pymongo import Connection\n",
    "# connection = Connection()#這是在自己的本機建的，所以用connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'comments',\n",
       " u'clean_comment',\n",
       " u'posts',\n",
       " u'pure_ke_user_copy',\n",
       " u'detector_one_by_one',\n",
       " u'user']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = client.Candidate\n",
    "db.collection_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 連結sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "con = sqlite3.connect('../thesis/candidate.sqlite3')\n",
    "c = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1044de500>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 刪除一個資料表\n",
    "# con.execute('''DROP TABLE comments''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1044de650>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create table\n",
    "con.execute('''CREATE TABLE comments\n",
    "             (user_id text, \n",
    "             user_name text, \n",
    "             comment_id text PRIMARY KEY, \n",
    "             comment text, \n",
    "             comment_time date,\n",
    "             page_name text, \n",
    "             post_id text,\n",
    "             post_time date)''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 存入sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-08\n",
      "2017-02-08\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-08\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-08\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-09\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-07\n",
      "2017-02-07\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-09\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-08\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-08\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-08\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-08\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-09\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-07\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-08\n",
      "2017-02-08\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-08\n",
      "2017-02-06\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-08\n",
      "2017-02-08\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-08\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-07\n",
      "2017-02-07\n",
      "2017-02-07\n",
      "2017-02-07\n",
      "2017-02-09\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-07\n",
      "2017-02-06\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-07\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-08\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-08\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-07\n",
      "2017-02-07\n",
      "2017-02-07\n",
      "2017-02-07\n",
      "2017-02-07\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-07\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-10\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-07\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-06\n",
      "2017-02-09\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-08\n",
      "2017-02-05\n",
      "2017-02-08\n",
      "2017-02-07\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-09\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-07\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-09\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-07\n",
      "2017-02-07\n",
      "2017-02-06\n",
      "2017-02-07\n",
      "2017-02-07\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-09\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-08\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-09\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-08\n",
      "2017-02-05\n",
      "2017-02-08\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-09\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-09\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-08\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-10\n",
      "2017-02-05\n",
      "2017-02-07\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-05\n",
      "2017-02-05\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-06\n",
      "2017-02-07\n"
     ]
    }
   ],
   "source": [
    "for cc in first_c_data[0:1]:\n",
    "    for c in cc:\n",
    "        print c['created_time'][0:10]\n",
    "# SELECT convert(datetime, 'Oct 23 2012 11:01AM', 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "for cc in first_c_data:\n",
    "    for c in cc: \n",
    "        pt = datetime.datetime.strptime(c['created_time'], \"%Y-%m-%dT%H:%M:%S+%f\")\n",
    "        t = pt.timetuple()  #是一個神奇的函式\n",
    "        y = c['created_time'][0:4][-2:]\n",
    "        post_time = c['created_time'][0:10]\n",
    "        row = [ c['from']['id'],\n",
    "                c['from']['name'],\n",
    "                c['id'],\n",
    "                c['message'],\n",
    "                str(t[1])+'/'+str(t[2])+'/'+str(y)+' '+str(t[3])+':'+str(t[4]),\n",
    "               facebook_page_name,\n",
    "               c['id'].split('_')[0],\n",
    "                post_time,]\n",
    "\n",
    "        try:\n",
    "            con.execute(\"INSERT INTO comments (user_id, user_name, comment_id, comment, comment_time,page_name, post_id, post_time) VALUES (?,?,?,?,?,?,?,?)\",row)\n",
    "        except sqlite3.IntegrityError:\n",
    "            pass\n",
    "#             print('ERROR: ID already exists in PRIMARY KEY column {}'.format(c['id']))    \n",
    "\n",
    "con.commit()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 處理 comments區域 --> 存入叫做\"comments\"的 collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment count: 2229\n",
      "reaction count: 2407\n"
     ]
    }
   ],
   "source": [
    "#讀檔，把comment跟reaction分開\n",
    "import json\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "facebook_id = '46251501064' #Tsai\n",
    "facebook_page_name = 'Tsai'\n",
    "# facebook_id = '136845026417486' #Ke\n",
    "# facebook_page_name = 'Ke'\n",
    "# facebook_id = '188311137478' #ChinaTimes \n",
    "# facebook_page_name = 'ChinaTimes'\n",
    "# facebook_id = '241284961029'\n",
    "# facebook_page_name = 'udn' \n",
    "# facebook_id = '394896373929368' \n",
    "# facebook_page_name = 'ltn' \n",
    "# facebook_id = '232633627068' \n",
    "# facebook_page_name = 'AppleDaily'\n",
    "\n",
    "file_path = 'data'+'/'+facebook_id+'/'\n",
    "onlyfiles = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
    "\n",
    "## 把 第一層回覆 與 reaction以後的分開放\n",
    "comment_list, reac_list = [],[]\n",
    "\n",
    "for f in onlyfiles:\n",
    "    if f.endswith('.json'):\n",
    "        if f.startswith('comment'):\n",
    "            comment_list.append(f)\n",
    "        if f.startswith('reaction'):\n",
    "            reac_list.append(f)\n",
    "print 'comment count:', len(comment_list)\n",
    "# print comment_list[0]\n",
    "print 'reaction count:', len(reac_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#檢查有沒有重複抓取的comment跟reaction，如果有的話要刪掉\n",
    "comment_id={}\n",
    "for c in comment_list:\n",
    "    if not comment_id.has_key(c.split('-')[1].split('.')[0]):\n",
    "        comment_id[c.split('-')[1].split('.')[0]]=0\n",
    "    comment_id[c.split('-')[1].split('.')[0]]+=1\n",
    "for co in comment_id:\n",
    "    if comment_id[co]>2:\n",
    "        print co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2412\n"
     ]
    }
   ],
   "source": [
    "#把 posts的資料load進來\n",
    "p_file_path = 'data'+'/'+facebook_id+'/'+'posts.json'\n",
    "\n",
    "import operator\n",
    "posts = []\n",
    "with open(p_file_path) as ff:\n",
    "    for line in ff:\n",
    "        posts.append(json.loads(line))\n",
    "\n",
    "# for v, c in enumerate(posts[0]):\n",
    "#     print v\n",
    "print len(posts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### 第一層回覆的檔案\n",
    "import operator\n",
    "\n",
    "first_c_data = []\n",
    "comment_id = [] #post_id\n",
    "for h, j in enumerate(comment_list):\n",
    "#     print comment_list[h] # 檔名（為貼文的id）\n",
    "    comment_id.append(comment_list[h].split('-')[1].split('.')[0])\n",
    "    \n",
    "    with open(file_path+comment_list[h]) as fff:\n",
    "        for line in fff:\n",
    "            first_c_data.append(json.loads(line))\n",
    "# print comment_id \n",
    "# print first_c_data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 寫進叫做 “comments\"的collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/TingYen/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:41: DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1240537\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "# collection名＋.find() 可以印出在一個collection中的所有內容 --> 不要印，很恐怖～\n",
    "\n",
    "for cc in first_c_data:\n",
    "    for c in cc: \n",
    "        pt = datetime.datetime.strptime(c['created_time'], \"%Y-%m-%dT%H:%M:%S+%f\")\n",
    "        t = pt.timetuple()  #是一個神奇的函式\n",
    "        y = c['created_time'][0:4][-2:]\n",
    "        k = c['id'].split('_')[0]\n",
    "        for o in posts[0]:\n",
    "            if k == o['id'].split('_')[1]:\n",
    "#                 print o['id']\n",
    "                post_time = datetime.datetime.strptime(o['created_time'], \"%Y-%m-%dT%H:%M:%S+%f\")\n",
    "                pp = post_time.timetuple()\n",
    "\n",
    "    #     print t[0] #year\n",
    "    #     print t[1] #month\n",
    "    #     print t[2] #date\n",
    "#         print t[3] #hour\n",
    "    #     print t[4] #min\n",
    "    #     print t[5] #sec\n",
    "    #     print pt_3, pt_2\n",
    "\n",
    "    # for p in collect.find()[77:78]:\n",
    "    #     print p\n",
    "\n",
    "                db.comments.insert({'comment':c['message'],\n",
    "                                'post_time':str(pp[1])+'/'+str(pp[2])+'/'+str(y)+' '+str(pp[3])+':'+str(pp[4]),\n",
    "                                'user_id':c['from']['id'],\n",
    "                                'time':str(t[3])+':'+str(t[4])+':'+str(t[5]),\n",
    "                                'user_name':c['from']['name'],\n",
    "                                'comment_id':c['id'],\n",
    "                                'month':t[1],\n",
    "                                'post_id':c['id'].split('_')[0],\n",
    "                                'page_name':facebook_page_name,\n",
    "                                'year':t[0],\n",
    "                                'date':str(t[1])+'/'+str(t[2])+'/'+str(y)+' '+str(t[3])+':'+str(t[4]),\n",
    "                                'page_id':facebook_id,\n",
    "                                'day':t[2],\n",
    "                                'comment_count':c['comment_count'],\n",
    "                                'like_count':c['like_count']})\n",
    "               \n",
    "db.comments.count()\n",
    "db.update\n",
    "# comments.update()\n",
    "print db.comments.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 處理post 區域 --> 存入叫做 FBcollection的collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3502\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "# collection名＋.find() 可以印出在一個collection中的所有內容 --> 不要印，很恐怖～\n",
    "    \n",
    "for v, b in enumerate(posts[0]): \n",
    "    pt = datetime.datetime.strptime(b['created_time'], \"%Y-%m-%dT%H:%M:%S+%f\")\n",
    "    t = pt.timetuple()  #是一個神奇的函式\n",
    "    \n",
    "    m = ''\n",
    "    try:\n",
    "        m = b['message']\n",
    "\n",
    "    #     print t[0] #year\n",
    "    #     print t[1] #month\n",
    "    #     print t[2] #date\n",
    "    #     print t[3] #hour\n",
    "    #     print t[4] #min\n",
    "    #     print t[5] #sec\n",
    "\n",
    "        db.posts.insert({'Created_Time':str(t[1])+'/'+str(t[2])+'/'+str(t[0])+' '+str(t[3])+':'+str(t[4]),\n",
    "                        'Page_ID':facebook_id,\n",
    "                        'Message':m,\n",
    "                        'Page_Name':facebook_page_name,\n",
    "                        'Year':t[0],\n",
    "                        'Day':t[2],\n",
    "                        'URL':b['permalink_url'],\n",
    "                        'Time':str(t[3])+':'+str(t[4])+':'+str(t[5]),\n",
    "                        'Month':t[1],\n",
    "                        'Post_ID':b['id']})\n",
    "    except:\n",
    "        m = ''\n",
    "        db.posts.insert({'Created_Time':str(t[1])+'/'+str(t[2])+'/'+str(t[0])+' '+str(t[3])+':'+str(t[4]),\n",
    "                        'Page_ID':facebook_id,\n",
    "                        'Message':m,\n",
    "                        'Page_Name':facebook_page_name,\n",
    "                        'Year':t[0],\n",
    "                        'Day':t[2],\n",
    "                        'URL':b['permalink_url'],\n",
    "                        'Time':str(t[3])+':'+str(t[4])+':'+str(t[5]),\n",
    "                        'Month':t[1],\n",
    "                        'Post_ID':b['id']})\n",
    "#         print 'post_id', c['id']\n",
    "# db.posts.find()\n",
    "db.update\n",
    "db.posts.count()\n",
    "print db.posts.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 處理reaction 區域\n",
    "1. 按照不同的reactions存\n",
    "2. 存入叫做 reactions的collection\n",
    "3. 如果沒有任何一種reaction的話就不存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2463\n"
     ]
    }
   ],
   "source": [
    "#load reactions.json\n",
    "# reac_list --> reactions data inside\n",
    "import operator\n",
    "reac_data = {}\n",
    "for h, j in enumerate(reac_list):\n",
    "#     print reac_list[h] # 檔名（為貼文的id）\n",
    "    reac_id = reac_list[h].split('-')[1].split('.')[0]\n",
    "    \n",
    "    with open(file_path+reac_list[h]) as fff:\n",
    "        for line in fff:\n",
    "            reac_data[reac_id] = json.loads(line)\n",
    "# print reac_data.keys()\n",
    "\n",
    "for rr,rv in reac_data.items():\n",
    "    LIKE,SAD,ANGRY,WOW,HAHA,LOVE = [],[],[],[],[],[]\n",
    "    rdata = []\n",
    "    if len(rv) == 1:  #如果reaction只有一串（有時候量太大會有一串以上）\n",
    "        if len(rv[0]) == 1: # [[\"\"]]  #如果reactions中什麼都沒有，就略過\n",
    "            pass\n",
    "        else:\n",
    "            if \"paging\" in rv[0]:\n",
    "                rdata = rv[0]['data']  #有些reactions中有\"paging\",那資料是rv[0]['data']\n",
    "            else:\n",
    "                rdata = rv[0]  #如果沒有\"paging\",那資料就是rv[0]\n",
    "            \n",
    "    else:\n",
    "        for rd in range(len(rv)): #如果是一串以上\n",
    "            try: \n",
    "                rdata.append(rv[rd]['data'][0])  #試著把資料中所有的'data'[0]加進去\n",
    "            except:\n",
    "                try:\n",
    "                    if len(rv[rd][0])==1:  #如果裡面是空的\n",
    "                        print rv[rd]\n",
    "                        continue\n",
    "                    else:\n",
    "                        rdata = rv[rd][0] \n",
    "                except:\n",
    "                    print rv[rd]\n",
    "                        \n",
    "#     fname = file_path + '000-%s.json'%(rr)\n",
    "#     with open(fname, 'w') as fout:\n",
    "#         json.dump(rdata, fout)\n",
    "    \n",
    "    for r in range(len(rdata)):\n",
    "        try:\n",
    "    #     print rdata[r]['type'],rdata[r]['id'] #LIKE 1339671589393499\n",
    "            if rdata[r]['type'] == 'LIKE':\n",
    "                LIKE.append(rdata[r]['id'])\n",
    "            if rdata[r]['type'] == 'SAD':\n",
    "                SAD.append(rdata[r]['id'])\n",
    "            if rdata[r]['type'] == 'ANGRY':\n",
    "                ANGRY.append(rdata[r]['id'])\n",
    "            if rdata[r]['type'] == 'WOW':\n",
    "                WOW.append(rdata[r]['id'])\n",
    "            if rdata[r]['type'] == 'HAHA':\n",
    "                HAHA.append(rdata[r]['id'])\n",
    "            if rdata[r]['type'] == 'LOVE':\n",
    "                LOVE.append(rdata[r]['id'])\n",
    "        except:\n",
    "#             print rr\n",
    "            pass\n",
    "    ###取一些post的資料加進去###\n",
    "    p_link = []\n",
    "    for o in posts[0]:\n",
    "        if rr == o['id']:\n",
    "            p_link = o['permalink_url']\n",
    "###寫入資料庫###\n",
    "    db.reactions.insert({'LIKE':LIKE,\n",
    "                    'SAD':SAD,\n",
    "                    'ANGRY':ANGRY,\n",
    "                    'WOW':WOW,\n",
    "                    'HAHA':HAHA,\n",
    "                    'LOVE':LOVE,\n",
    "                    'Page_ID':facebook_id,\n",
    "                    'Page_Name':facebook_page_name,\n",
    "                    'Post_ID':rr,\n",
    "                    'Link':p_link})\n",
    "db.reactions.count()\n",
    "db.update\n",
    "# comments.update()\n",
    "print db.reactions.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
